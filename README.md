## Cohen's Kappa

We added Cohenâ€™s Kappa in TF-addons a while back. The current [implementation](https://github.com/tensorflow/addons/blob/master/tensorflow_addons/metrics/cohens_kappa.py) accepts a 1-D array of predictions and and 1-D array of true labels, and returns the result.  A typical example looks like this:

```python
actuals = np.array([4, 4, 3, 4, 2, 4, 1, 1], dtype=np.int32)
preds = np.array([4, 4, 3, 4, 4, 2, 1, 1], dtype=np.int32)

m = tfa.metrics.CohenKappa(num_classes=5)
m.update_state(actuals, preds)

print('Final result: ', m.result().numpy()) 

```

## Limitations of the current implementation
The current implementation can't directly be used with `model.fit(..)` because the model always produces `batches` of predictions. Although this can be solved by simply `reshaping`, I found that the problem isn't as straightforward as it seems. 

There are three different sceanrios we have to consider here. Let me try to eleborate on this:

### Case 1: Binary classification problem
In this case, the model would look something like this:
```python

model = Sequential()
model.add(..)
...
model.add(Dense(1, activation='sigmoid'))
model.compile(loss='binary_crossentropy', optimier='sgd', metrics=['accuracy', 
                                                                    CohensKappa(num_classes=2)])
model.fit(..)

```
In this case

`y_pred` shape: (num_samples, 1)<br>
`y_true` shape: (num_samples, )<br>

The call to `update_state()` in this scenario should do something like this:<br>
```python

def update_state(self, y_true, y_pred, sample_weight=None):
    y_true = tf.cast(y_true, dtype=tf.int64)
    y_pred = tf.cast(y_pred >= 0.5, dtype=tf.int64)

    # compute the new values of the confusion matrix
    new_conf_mtx = tf.math.confusion_matrix(
        labels=y_true,
        predictions=y_pred,
        num_classes=self.num_classes,
        weights=sample_weight,
        dtype=tf.float32)

    # update the values in the original confusion matrix
    return self.conf_mtx.assign_add(new_conf_mtx)

```

### Case 2: Multiclass Classification problem
In this case, the model would look something like this:
```python

model = Sequential()
model.add(..)
...
model.add(Dense(num_classes, activation='softmax'))
model.compile(loss='categorical_crossentropy', optimier='sgd', metrics=['accuracy', 
                                                                    CohensKappa(num_classes=num_classes)])
model.fit(..)

```
In this case

`y_pred` shape: (num_samples, num_classes)<br>
`y_true` shape: (num_samples, num_classes) if `onr-hot encoded` or (num_samples,) if `sparse labels` are used

The call to `update_state()` in this scenario should do something like this:<br>
```python

def update_state(self, y_true, y_pred, sample_weight=None):
    y_true = tf.cast(y_true, dtype=tf.int64)
    y_pred = tf.cast(tf.argmax(y_pred), dtype=tf.int64)
    
    ###### Checks ################
    #
    # We need some checks here depending on whether the true labels are one-hote encoded 
    # or are just sparse. Until unless we do this check we can't get the right shape
    # for y_true and y_pred
    #
    ################################

    # compute the new values of the confusion matrix
    new_conf_mtx = tf.math.confusion_matrix(
        labels=y_true,
        predictions=y_pred,
        num_classes=self.num_classes,
        weights=sample_weight,
        dtype=tf.float32)

    # update the values in the original confusion matrix
    return self.conf_mtx.assign_add(new_conf_mtx)

```
